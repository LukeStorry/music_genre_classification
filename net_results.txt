Given (raw, max, maj, ep)
=========================

shallow  62.05, 81.20, 75.20, 	100
deep     69.17, 81.20, 81.60, 	100
shallow  61.15, 78.80, 75.20, 	200
deep     69.12, 84.00, 84.40,   200


Our implementation (raw, max, maj, ep)
======================================

shallow 67.00, 85.20, 84.00,    100
shallow 68.80, 81.20, 79.60, 	100 (Batch Norm)
shallow 62.10, 81.60, 77.60, 	100 (Aug)
shallow 65.20, 82.40, 79.60, 	100 (Batch Norm + Aug)

deep 	69.50, 83.20, 82.40	100
deep	71.80, 86.40, 84.40	100 (Batch Norm)
deep	69.90, 85.20, 84.40	100 (Aug)
deep	71.60, 87.20, 83.20	100 (Batch Norm + Aug)

shallow 63.50, 77.20, 77.60,	200
shallow 68.80, 85.20, 80.80, 	200 (Batch Norm)
shallow 65.00, 84.40, 80.00,    200 (Aug)
shallow 65.40, 79.20, 80.40,    200 (Batch Norm + Aug)

deep	69.30, 82.40, 79.20 	200
deep	69.00, 82.00, 80.80	200 (Batch Norm)
deep	69.20, 84.40, 82.80	200 (Aug)
deep	73.30, 87.20, 87.20	200 (Batch Norm + Aug)


-- Batch norm and Aug don't give any improvement over base implementation
   for shallow network trained for 100 epochs

-- Batch norm and Aug give improvements for the deep network trained for
   100 epochs, especially max probability measure

-- Batch norm gives the best improvement across the board for shallow network
   trained for 200 epochs

-- good improvements across the board for deep network with both aug and
   batch norm trained for 200 epochs
